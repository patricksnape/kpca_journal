\section{Introduction}\label{sec:introduction}
\IEEEPARstart{S}{ince} Lucas and Kanade first proposed their optical-flow algorithm \cite{RefWorks:71}, it has become the de facto choice for image alignment. Today, LK does not represent a single algorithm, but rather a broad family of algorithms. These algorithms can be categorised as seeking to minimise a given cost function by optimising over a parametrised warp function. Many different approaches have been proposed to solve the original LK algorithm, but by far the most popular is the inverse compositional (IC) update proposed by Baker and Matthews \cite{RefWorks:10}. In \cite{RefWorks:10}, Baker and Matthews show that the IC update gives a very computationally efficient method of solving the $\ltwo$ norm minimisation. 

Although efficient, the sum of squared deviations (SSD) used in the IC update is not robust. Therefore, more recent work has concentrated on robustness to outliers such as occlusions and variable illumination. These attempts fall roughly in to two major categories: replacing the SSD with a robust objective function \cite{RefWorks:59, RefWorks:72, RefWorks:53, RefWorks:274} or replacing pixel intensities with a more informative feature space \cite{RefWorks:73, RefWorks:6, RefWorks:273}. For example, Evangelidis and Psarakis \cite{RefWorks:59} replace the SSD with the Enhanced Correlation Coefficient (ECC) which seeks to minimise over the normalised pixel intensities. They provide an IC update of the ECC cost function and prove its invariance to illumination changes. Illumination invariance was also shown by Dowsen and Bowden in \cite{RefWorks:72}. Here, they propose a mutual information based cost function and, with additional assumptions, also give a computationally efficient algorithm. 

Lucey et al. \cite{RefWorks:67, RefWorks:73} showed that SSD measures can be robust if performed on features other than pixel intensities. In particular, they formulate the LK algorithm within the 2D Fourier domain and show that image alignment on banks of filter responses is equivalent to a weighted alignment of pixel intensities. Cootes and Taylor \cite{RefWorks:273} use local image features in the form of edge orientations in order to exploit the underlying object structure.

Although the Lucas-Kanade (LK) algorithm describes a gradient descent methodology for aligning arbitrary objects, much of the literature concentrates on its use in facial alignment. This is due, in part, to the large number of facial images available for study, as well as interesting uses of facial analysis in security, medicine and entertainment. More recently, cheap consumer hardware, such as the Microsoft Kinect, has seen increased availability of depth images of faces. Depth images have the advantage of being a more descriptive medium than pixel intensities, as they are insensitive to illumination and give an explicit representation of shape. The previously discussed LK algorithms, whilst robust for intensity images, do not make use of this more powerful representation. In particular, they focus on insensitivity to illumination variation, which is not an issue for depth data. However, depth data suffers from its own issues, most notably lack of spatial accuracy and noise. For this reason, we propose a robust feature space for depth data, which comes in the form of normals.

Normals, in depth images, are defined as the vectors that lie perpendicular to the object surface at a given point. A depth image can be seen as a surface with a triangulation that is given implicitly by its discrete gridded nature. Each pixel is a member of multiple triangles and a normal can be calculated per-triangle. Therefore, the per-pixel normal is defined as the mean of the per-triangle normals that the pixel is a member of. Normals are most commonly investigated in conjunction with depth recovery techniques such as Shape-From-Shading (SFS) \cite{RefWorks:249, RefWorks:252, RefWorks:270, RefWorks:225} and photometric stereo \cite{RefWorks:268, RefWorks:108}. Shape-From-X techniques, including SFS, seek to recover shape from images by using different cues within an image. In the case of SFS, shape is recovered from a single image, under a single point light source, by assuming the object to be smooth and exhibit lambertian reflectance. However, SFS is, in general, an ill-defined problem. To overcome this, Smith and Hancock \cite{RefWorks:86, RefWorks:90} proposed a statistical prior on normals in facial images that produces accurate results with low-computational overhead. Their major contribution, however, was in noting that linear statistical analysis cannot be applied directly to normals. This is due to the fact that distances between normals are non-linear, and are actually best described as paths along the surface of a unit sphere. Smith and Hancock propose two separate methodologies for performing statistical analysis on normals. In \cite{RefWorks:90} they propose the Azimuthal Equidistant Projection (AEP), which projects normals on to their local tangent plane and allows for linear analysis in the tangent space. In \cite{RefWorks:86}, they extend the Principal Geodesic Analysis (PGA) proposed by Fletcher et al. \cite{RefWorks:100} to the domain of normals.

Unfortunately, even robust image alignment algorithms are not capable of handling large variations in appearance. In faces, these variations include pose, gender and identity. For this reason, Active Appearance Models (AAMs) were proposed \cite{RefWorks:95,RefWorks:227}. AAMs extend the LK algorithm to include statistical priors on appearance and shape and allow for complex object alignment. AAMs focus on modelling appearance variation according to a set of linear basis that is learnt offline. In the case of faces, the appearance model is able to represent changes in pose and identity. However, the canonical AAM as described by \cite{RefWorks:95} uses an SSD objective function and thus is not robust to outliers. In depth data, these outliers include occlusions and the noise within the data.

3D Morphable Models (3DMM) \cite{RefWorks:96}, represent the state-of-the-art for statistical fitting algorithms. 3DMMs combine a more complex model of appearance, shape and lighting than AAMs, and thus are more accurate at the expense of being less efficient. Even the more efficient inverse alignment method of \cite{RefWorks:275} is not able to match the real-time capabilities of AAMs \cite{RefWorks:233, RefWorks:236}. Many attempts have been made to recover 3D shape using AAMs \cite{RefWorks:233, RefWorks:236, RefWorks:258, RefWorks:257}. These attempts involve using a 3D shape prior in order to infer the depth from the sparse landmarks. Given that depth images already encode all three-dimensions, it is not necessary to couple our AAM with a 3D sparse shape model. Fanelli et al. \cite{RefWorks:236}, inspired by \cite{RefWorks:276}, used a random forest based approach to provide real-time fitting using depth images. However, due to the cascade of regressors used, their method requires training on far more images than a simple gradient descent based AAM such as ours.

In this work we are interested in robust facial alignment in depth images. We seek to align faces with changing identity and pose, which is possible through the use of algorithms such as AAMs. However, we wish to perform the alignment on noisy data with very little pre-processing. To achieve this, we propose the use of normals to minimise the effect of outliers. The use of normals as a robust subspace is motivated by previous work on using orientations for object alignment \cite{RefWorks:273, RefWorks:6, RefWorks:272}. Since normals encode the orientation of a surface, we can exploit previous work on the robustness of orientation features. For example, Tzimiropoulos et al. \cite{RefWorks:5} have shown that the cosine of orientations represent a theoretically robust subspace for linear analysis. By providing an angular representation of normals, we show that normals also exhibit a theoretically robust subspace.

In order to use normals as an appearance space within AAMs, we need to be able to perform statistical analysis on normals. Therefore, we present a kernel-based framework for non-linear analysis of normals. Due to the generality of our kernel-based framework, we also present results within the SFS framework of \cite{RefWorks:90}.

Summarising, our key contributions are:
%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{itemize}
  \item We use the insight given by the theoretical robustness of the cosine correlation and propose a novel cost function for the LK algorithm based on the cosine of the angle between normals.
  \item We provide a kernel-based framework for performing statistical component analysis of normals. We formulate two existing projection operations, the Azimuthal Equidistant Projection \cite{RefWorks:90} and Principal Geodesic Analysis \cite{RefWorks:86} within this framework.
  \item We provide a novel robust kernel based on the cosine of the angles between normals. We also show that components can be extracted directly from normals, which becomes clear within the kernel framework.
  \item Finally, we use our kernel framework to provide a robust AAM for facial depth images and show it's substantial performance improvement over raw depth data.
\end{itemize}
%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Notation of Normals}\label{subsec:notation-normals}
We are interested in image-based alignment and analysis and so assume that we are dealing with needle-maps. A needle-map describes a surface $z(i, j)$ in terms of the normal $\boldsymbol{n}(i, j) = [x_{ij}, y_{ij}, z_{ij}]^T$, aligned such that all normals point towards the camera plane. In the case of a set of training images, as used in statistical analysis, we denote the vector of normals of length $N$, for image $k$, as $\boldsymbol{x}_k = (x_k^1, y_k^1, z_k^1, \ldots, x_k^N, y_k^N, z_k^N)^T$.
%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Notation of LK}\label{subsec:notation-lk}
When referring to the operations performed by the LK algorithm we will use the following notations, borrowed from \cite{RefWorks:67}. Vectors are always presented in lower case bold, as in normals ($\boldsymbol{n}$), matrices are in upper case bold ($\boldsymbol{X}$) and scalars in lower case ($x$). Images are denoted in capitalised form as in $I$. Warp functions $\mathcal{W}(\boldsymbol{x}_i;\p) = \left[ \mathcal{W}_x(\boldsymbol{x}_i;\p), \mathcal{W}_y(\boldsymbol{x}_i;\p) \right]$ express the warping of the $i$th 2D coordinate vector $\boldsymbol{x}_i = [x_i, y_i]^T$ by a set of parameters $\p = \left[p(1), ..., p(n)\right]^T$, where $n$ is the number of warp parameters. Similar to the normal notation, $\boldsymbol{x} = \left[ x_1, y_1, \ldots, x_D, y_D \right]$ represents the concatenated vector of coordinates, of length $D$, which allows the definition of a single warp for an entire image, $\mathcal{W}(\boldsymbol{x};\p) = \left[ \mathcal{W}_x(\boldsymbol{x}_1;\p), \mathcal{W}_y(\boldsymbol{x}_1;\p), \ldots, \mathcal{W}_x(\boldsymbol{x}_D;\p), \mathcal{W}_y(\boldsymbol{x}_D;\p)\right]$. We assume that the identity warp is found when $\p = \zero$, which implies that $\mathcal{W}(\boldsymbol{x};\p) = \boldsymbol{x}$. The abuse of notation found in \cite{RefWorks:67} is followed, so that we define the warping of an image $I$ by parameter vector $\p$ as $I(\p) = I(\mathcal{W}(\boldsymbol{x};\p))$, where $I(\p)$ is a single column vector of concatenated pixels.